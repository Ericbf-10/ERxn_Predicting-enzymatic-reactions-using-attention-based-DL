{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bcfde7-c774-4ca3-8b1d-01b1df546128",
   "metadata": {},
   "source": [
    "# Molecular Transformer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1edb270a-d110-429f-86db-cbfd43aa8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math,copy,re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(\"ignore\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db15c8f-f742-4ad2-aa93-a96012b37ec0",
   "metadata": {},
   "source": [
    "## Smile tokenizer\n",
    "\n",
    "Canonical smiles were tokenized using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "59f489ad-3266-4320-a5cc-32f65d98f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a0575-4daf-4905-9534-616a833f0971",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "the dataset of canonical smiles, split in source and target are here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ef800fa4-a306-47c5-8260-479c97650e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: C ( C ) N ( C C ) C C . C ( C ) S ( Cl ) ( = O ) = O . C C O C C . O C C Br\n",
      "\n",
      "tgt: C C S ( = O ) ( = O ) O C C Br\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_training_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/src-train.txt'\n",
    "src_test_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/src-test.txt'\n",
    "src_valid_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/src-val.txt'\n",
    "tgt_training_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/tgt-train.txt'\n",
    "tgt_test_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/tgt-test.txt'\n",
    "tgt_valid_data_path = '../data/mol_transformer/data/STEREO_mixed_augm/tgt-val.txt'\n",
    "\n",
    "src = ''\n",
    "with open(src_training_data_path, 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        src = line\n",
    "        break\n",
    "\n",
    "tgt = ''\n",
    "with open(tgt_training_data_path, 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        tgt = line\n",
    "        break\n",
    "        \n",
    "print('src:', src)\n",
    "print('tgt:', tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0360f83-2f43-4589-be80-8cacc6805ada",
   "metadata": {},
   "source": [
    "## Building a vocabulary\n",
    "\n",
    "A vocabulary needs to be created for the tokenized smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d694dc8b-7131-43e3-a359-b35a6212c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3811102lines [00:10, 371891.05lines/s]\n"
     ]
    }
   ],
   "source": [
    "files = [src_training_data_path,\n",
    "         src_test_data_path,\n",
    "         src_valid_data_path,\n",
    "         tgt_training_data_path,\n",
    "         tgt_test_data_path,\n",
    "         tgt_valid_data_path\n",
    "        ]\n",
    "\n",
    "def yield_tokens():\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            for example in f:\n",
    "                tokens = example.replace('\\n','').split(' ')\n",
    "                yield tokens\n",
    "\n",
    "token_generator = yield_tokens()\n",
    "\n",
    "vocab = build_vocab_from_iterator(token_generator)\n",
    "#vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386c955-518c-4e8a-b80b-46656362311d",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a0a7f6e5-f5e3-42a2-9740-7f9cb012bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RxnDataset(Dataset):\n",
    "    def __init__(self, src_path, tgt_path, vocab):\n",
    "        self.src_data_path = src_path\n",
    "        self.tgt_data_path = tgt_path\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.src_data_path, 'r') as f:\n",
    "            return len(f.readlines())\n",
    "\n",
    "    def __getitem__(self, index, sos_token=0):\n",
    "        src_path = self.src_data_path\n",
    "        tgt_path = self.tgt_data_path\n",
    "        vocab = self.vocab\n",
    "        \n",
    "        src = linecache.getline(src_path, index + 1) # linecache indexing starts at 1 for some reason\n",
    "        tgt = linecache.getline(tgt_path, index + 1)\n",
    "        \n",
    "        src = torch.tensor(\n",
    "            [vocab[token] for token in src.replace('\\n','').split(' ')]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        tgt = torch.tensor(\n",
    "            [vocab[token] for token in tgt.replace('\\n','').split(' ')]\n",
    "        )\n",
    "        sos_token = torch.Tensor([sos_token])\n",
    "        tgt =  torch.concat((sos_token,tgt), dim=0).to(int)\n",
    "        return (src, tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9ce60-f4ee-41c6-8bbb-070a2d0cc540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loader and collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f19c1ec7-32d6-4222-9117-7eb9cfe9fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RxnDataset(src_training_data_path,\n",
    "                           tgt_training_data_path,\n",
    "                           vocab\n",
    "                          )\n",
    "\n",
    "test_dataset = RxnDataset(src_test_data_path,\n",
    "                           tgt_test_data_path,\n",
    "                           vocab\n",
    "                          )\n",
    "\n",
    "valid_dataset = RxnDataset(src_valid_data_path,\n",
    "                           tgt_valid_data_path,\n",
    "                           vocab\n",
    "                          )\n",
    "\n",
    "train_data_iter = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2fa7ba9d-2bde-4f4b-b9ac-26c03923c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  4,  3,  5, 11,  4,  3,  3,  5,  3,  3, 10,  3,  4,  3,  5, 17,  4,\n",
       "         15,  5,  4,  8,  6,  5,  8,  6, 10,  3,  3,  6,  3,  3, 10,  6,  3,  3,\n",
       "         21]),\n",
       " tensor([ 0,  3,  3, 17,  4,  8,  6,  5,  4,  8,  6,  5,  6,  3,  3, 21]))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386afa7-500b-4d11-a2c0-809d8bda1b67",
   "metadata": {},
   "source": [
    "## Data loader and collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "81c9c930-8acd-4f48-9a72-989602adf1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "BATCH_SIZE =32\n",
    "\n",
    "def pad_collate(batch, padding_value: int = 1):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=padding_value)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=pad_collate,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=pad_collate,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=pad_collate,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "51645510-d2bd-4188-9772-00e5fe5840fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56412 1571 1567\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(test_loader), len(valid_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42955d7b-ac52-43fc-ada0-f0fc8a054f74",
   "metadata": {},
   "source": [
    "## One hot encoder\n",
    "The one hot encoder is later needed to train the model. The model makes predictions for\n",
    "the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fe198d7a-e4b4-45f5-a53d-945d91a5abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(v: Tensor, vocab_size: int) -> Tensor:\n",
    "    '''\n",
    "    Takes tokenized sentences and one hot encodes\n",
    "    them. Tokens have to be integer values.\n",
    "    Args:\n",
    "    -----\n",
    "    v : Tensor\n",
    "        shape (batch_size, seq_length)\n",
    "    Out:\n",
    "    ----\n",
    "    out : Tensor\n",
    "        shape (batch_size, seq_length, vocab_size)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    out = torch.zeros((v.size(0), v.size(1), vocab_size))\n",
    "    for batch in range(v.size(0)):\n",
    "        for i, token in enumerate(v[0,:]):\n",
    "            out[batch,i,token] = 1\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fd566-5f98-43a8-b74a-0bbe8f643500",
   "metadata": {},
   "source": [
    "# Transformer implementation\n",
    "\n",
    "you can ignore that for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4647d7ef-22c2-46c7-add0-7d099ff304f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 138]) torch.Size([32, 68])\n"
     ]
    }
   ],
   "source": [
    "for i, (src, tgt, _, _) in enumerate(train_loader):\n",
    "    # attach to device\n",
    "    break\n",
    "print(src.shape, tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8b57d638-7a3a-41e4-8ddd-af44e838f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512]) torch.Size([82, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "class Embedding(nn.Module):\n",
    "    '''\n",
    "    embeds sentence\n",
    "    Args:\n",
    "    -----\n",
    "    vocab_size : int\n",
    "        size of vocabulary\n",
    "        \n",
    "    embed_dim : int\n",
    "        embedding dimension\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        '''\n",
    "        forward pass\n",
    "        Args:\n",
    "        -----\n",
    "        x : Tensor\n",
    "            shape [batch_size, seq_length]\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        out : Tensor\n",
    "            shape [seq_length, batch_size, embed_dim]\n",
    "        '''\n",
    "        out = self.embed(x) # (batch_size, seq_length, embed_dim)\n",
    "        out = out.permute(1,0,2) # (seq_length, batch_size, embed_dim)\n",
    "        return out\n",
    "    \n",
    "embedding = Embedding(len(vocab))\n",
    "src_embed = embedding(src)\n",
    "tgt_embed = embedding(tgt)\n",
    "print(src_embed.shape, tgt_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "aa0275d3-e518-4b3d-a384-f9ca54994211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512]) torch.Size([82, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self,  embed_dim: int = 512, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "pos_encoding = PositionalEncoding()\n",
    "src_pos_embed = pos_encoding(src_embed)\n",
    "tgt_pos_embed = pos_encoding(tgt_embed)\n",
    "print(src_pos_embed.shape, tgt_pos_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "c6955420-034e-4043-a012-c3cc1cff5f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512]) torch.Size([32, 8, 142, 64]) torch.Size([32, 8, 142, 64]) torch.Size([32, 8, 142, 64])\n",
      "torch.Size([82, 32, 512]) torch.Size([32, 8, 82, 64]) torch.Size([32, 8, 82, 64]) torch.Size([32, 8, 82, 64])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    '''SelfAttention mechanism.\n",
    "    Args:\n",
    "    -----\n",
    "    dim : int\n",
    "        The out dimension of the query, key and value.\n",
    "    n_heads : int\n",
    "        Number of self-attention heads.\n",
    "    qkv_bias : bool\n",
    "        If True then we include bias to the query, key and value projections.\n",
    "    attn_p : float\n",
    "        Dropout probability applied to the query, key and value tensors.\n",
    "    proj_p : float\n",
    "        Dropout probability applied to the output tensor.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dim: int = 512, n_heads: int = 8, qkv_bias: bool = True,\n",
    "                 attn_p: float = 0.1, proj_p: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "    def forward(self, x, mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"Run forward pass.\n",
    "        Args:\n",
    "        -----\n",
    "        x : Tensor\n",
    "            shape [seq_len, batch_size, embedding_dim].\n",
    "        Returns:\n",
    "        --------\n",
    "        x : Tensor\n",
    "            x shape [seq_len, batch_size, embedding_dim].\n",
    "        q, k, v : Tensor\n",
    "            q, k, v shape [batch_size, n_heads, tgt_seq_length, head_dim]\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, dim = x.shape\n",
    "\n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "            \n",
    "        qkv = self.qkv(x)  # (seq_length, batch_size, 3 * dim)\n",
    "        qkv = qkv.permute(1,0,2) # (batch_size, seq_len, 3 * dim)\n",
    "\n",
    "        qkv = qkv.reshape(\n",
    "            batch_size, seq_len, 3, self.n_heads, self.head_dim\n",
    "        )  # (batch_size, seq_length + 1, 3, n_heads, head_dim)\n",
    "        \n",
    "        qkv = qkv.permute(\n",
    "            2, 0, 3, 1, 4\n",
    "        )  # (3, batch_size, n_heads, seq_length, head_dim)\n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # (batch_size, n_heads, seq_length, head_dim)\n",
    "\n",
    "        dp = torch.einsum('ijkl,ijml->ijkm', q, k) * self.scale  # k_t @ q (batch_size, n_heads, seq_length, seq_length)\n",
    "        \n",
    "        if mask is not None:\n",
    "            dp = dp.masked_fill(mask == float('-inf'), float('-inf'))\n",
    "            \n",
    "        scores = dp.softmax(dim=-1)  # (batch_size, n_heads, seq_length, seq_length)\n",
    "        scores = self.attn_drop(scores)\n",
    "        \n",
    "        weighted_avg = torch.einsum('ijkl,ijlm->kijm', scores, v)  # (seq_len, batch_size, n_heads, head_dim)\n",
    "        weighted_avg = weighted_avg.flatten(2)  # (seq_length, batch_size, dim)\n",
    "\n",
    "        x = self.proj(weighted_avg)  # (seq_length, batch_size, dim)\n",
    "        x = self.proj_drop(x)  # (seq_length, batch_size, dim)\n",
    "\n",
    "        return x, q, k, v\n",
    "        \n",
    "self_attention = SelfAttention()\n",
    "src_attn, src_q, src_k, src_v = self_attention(src_pos_embed)\n",
    "tgt_attn, tgt_q, tgt_k, tgt_v = self_attention(tgt_pos_embed)\n",
    "print(src_attn.shape, src_q.shape, src_k.shape, src_v.shape)\n",
    "print(tgt_attn.shape, tgt_q.shape, tgt_k.shape, tgt_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7f76fc62-3496-4212-b074-64716738b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512]) torch.Size([32, 8, 142, 64]) torch.Size([32, 8, 142, 64]) torch.Size([32, 8, 142, 64])\n",
      "torch.Size([82, 32, 512]) torch.Size([32, 8, 82, 64]) torch.Size([32, 8, 82, 64]) torch.Size([32, 8, 82, 64])\n"
     ]
    }
   ],
   "source": [
    "class EncoderDecoderAttention(nn.Module):\n",
    "    '''SelfAttention mechanism.\n",
    "    Args\n",
    "    ----\n",
    "    dim : int\n",
    "        The out dimension of the query, key and value.\n",
    "    n_heads : int\n",
    "        Number of self-attention heads.\n",
    "    qkv_bias : bool\n",
    "        If True then we include bias to the query, key and value projections.\n",
    "    attn_p : float\n",
    "        Dropout probability applied to the query, key and value tensors.\n",
    "    proj_p : float\n",
    "        Dropout probability applied to the output tensor.\n",
    "    '''\n",
    "    def __init__(self, dim: int = 512, n_heads: int = 8, qkv_bias: bool = True, \n",
    "                 attn_p: float = 0.1, proj_p: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.q_matrix = nn.Linear(dim,dim, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "    \n",
    "    def forward(self, x, k: Tensor=None, v: Tensor=None, mask: Tensor=None) -> Tensor:\n",
    "        \"\"\"Run forward pass.\n",
    "        Args\n",
    "        ----\n",
    "        x : Tensor\n",
    "            shape [seq_len, batch_size, embedding_dim].\n",
    "        Returns\n",
    "        -------\n",
    "        x : Tensor\n",
    "            x shape [seq_len, batch_size, embedding_dim].\n",
    "        q, k, v : Tensor\n",
    "            q, k, v shape [batch_size, n_heads, tgt_seq_length, head_dim]\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, dim = x.shape\n",
    "\n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "        \n",
    "        q = self.q_matrix(x)  # (tgt_seq_length, batch_size, dim)\n",
    "        q = q.permute(1,0,2) # (batch_size, tgt_seq_length, dim)\n",
    "    \n",
    "        q = q.reshape(\n",
    "            batch_size, seq_len, self.n_heads, self.head_dim\n",
    "        )  # (batch_size, tgt_seq_len, n_heads, head_dim)\n",
    "        \n",
    "        q = q.permute(\n",
    "            0, 2, 1, 3\n",
    "        )  # (batch_size, n_heads, tgt_seq_length, head_dim)\n",
    "       \n",
    "        dp = torch.einsum('ijml,ijkl->ijmk', q, k) * self.scale # k_t @ q (batch_size, n_heads, tgt_seq_len, src_seq_len)\n",
    "        \n",
    "        if mask is not None:\n",
    "            # TODO: masking does not work\n",
    "            dp = dp.masked_fill(mask == float('-inf'), float('-inf'))\n",
    "            \n",
    "        \n",
    "        scores = dp.softmax(dim=-1)  # (batch_size, n_heads, seq_length + 1, seq_length + 1)\n",
    "        scores = self.attn_drop(scores)\n",
    "        \n",
    "        weighted_avg = torch.einsum('ijkl,ijlm->kijm',scores, v) # (seq_length, batch_size, n_heads, head_dim)\n",
    "        \n",
    "        weighted_avg = weighted_avg.flatten(2)  # (seq_length, batch_size, dim)\n",
    "        \n",
    "        x = self.proj(weighted_avg)  # (seq_length, batch_size, dim)\n",
    "        x = self.proj_drop(x)  # (seq_length, batch_size, dim)\n",
    "\n",
    "        return x, q, k, v\n",
    "\n",
    "encoder_decoder_attention = EncoderDecoderAttention()\n",
    "tgt_attn, tgt_q, k, v = encoder_decoder_attention(tgt_pos_embed, src_k, src_v)\n",
    "print(src_attn.shape, src_q.shape, src_k.shape, src_v.shape)\n",
    "print(tgt_attn.shape, tgt_q.shape, tgt_k.shape, tgt_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "818fa389-4cbc-49a6-9566-56d29b10143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Multilayer perceptron.\n",
    "    Args\n",
    "    ----\n",
    "    in_features : int\n",
    "        Number of input features.\n",
    "    hidden_features : int\n",
    "        Number of nodes in the hidden layer.\n",
    "    out_features : int\n",
    "        Number of output features.\n",
    "    p : float\n",
    "        Dropout probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int = 512, hidden_features: int = 4*512, \n",
    "                 out_features: int = 512, p: float = 0.):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        \"\"\"Run forward pass.\n",
    "        Args\n",
    "        ----\n",
    "        x : torch.Tensor\n",
    "            Shape `(batch_size, n_patches + 1, in_features)`.\n",
    "        Returns\n",
    "        -------\n",
    "        x : torch.Tensor\n",
    "            Shape `(batch_size, n_patches +1, out_features)`\n",
    "        \"\"\"\n",
    "        x = self.fc1(\n",
    "            x\n",
    "        )  # (batch_size, n_patches + 1, hidden_features)\n",
    "        x = self.act(x)  # (batch_size, n_patches + 1, hidden_features)\n",
    "        x = self.drop(x)  # (batch_size, n_patches + 1, hidden_features)\n",
    "        x = self.fc2(x)  # (batch_size, n_patches + 1, out_features)\n",
    "        x = self.drop(x)  # (batch_size, n_patches + 1, out_features)\n",
    "\n",
    "        return x\n",
    "\n",
    "mlp = MLP()\n",
    "z = mlp(src_attn)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b8da047c-1f9b-4a77-b88e-214da41425b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 32, 512])\n",
      "torch.Size([32, 8, 142, 64]) torch.Size([32, 8, 142, 64])\n"
     ]
    }
   ],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer block.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Embeddinig dimension.\n",
    "    n_heads : int\n",
    "        Number of attention heads.\n",
    "    mlp_ratio : float\n",
    "        Determines the hidden dimension size of the `MLP` module with respect\n",
    "        to `dim`.\n",
    "    qkv_bias : bool\n",
    "        If True then we include bias to the query, key and value projections.\n",
    "    p, attn_p : float\n",
    "        Dropout probability.\n",
    "    Attributes\n",
    "    ----------\n",
    "    norm1, norm2 : LayerNorm\n",
    "        Layer normalization.\n",
    "    attn : Attention\n",
    "        Attention module.\n",
    "    mlp : MLP\n",
    "        MLP module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int = 512, n_heads: int = 8, mlp_ratio: float = 4.0, \n",
    "                 qkv_bias: bool = True, p: float = 0., attn_p: float = 0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.attn = SelfAttention(\n",
    "            dim,\n",
    "            n_heads=n_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            attn_p=attn_p,\n",
    "            proj_p=p\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        hidden_features = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(\n",
    "            in_features=dim,\n",
    "            hidden_features=hidden_features,\n",
    "            out_features=dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"Run forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(batch_size, n_patches + 1, dim)`.\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(batch_size, n_patches + 1, dim)`.\n",
    "        \"\"\"\n",
    "        attn, q, k, v = self.attn(x, mask)\n",
    "        attn_add_norm = self.norm1(attn + x)\n",
    "        z = self.mlp(attn_add_norm)\n",
    "        out = self.norm2(z+attn_add_norm)\n",
    "        \n",
    "        return out, k, v\n",
    "\n",
    "encoder_block = EncoderBlock()\n",
    "encoded_src, k, v = encoder_block(src_pos_embed)\n",
    "print(encoded_src.shape)\n",
    "print(k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ffc2bebf-313c-4413-8ced-22b180db83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Transformer block.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        Embeddinig dimension.\n",
    "    n_heads : int\n",
    "        Number of attention heads.\n",
    "    mlp_ratio : float\n",
    "        Determines the hidden dimension size of the `MLP` module with respect\n",
    "        to `dim`.\n",
    "    qkv_bias : bool\n",
    "        If True then we include bias to the query, key and value projections.\n",
    "    p, attn_p : float\n",
    "        Dropout probability.\n",
    "    Attributes\n",
    "    ----------\n",
    "    norm1, norm2 : LayerNorm\n",
    "        Layer normalization.\n",
    "    attn : Attention\n",
    "        Attention module.\n",
    "    mlp : MLP\n",
    "        MLP module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int = 512, n_heads: int = 8, mlp_ratio: float = 4.0, \n",
    "                 qkv_bias: bool = True, p: float = 0., attn_p: float = 0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.self_attn = SelfAttention(\n",
    "            dim,\n",
    "            n_heads=n_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            attn_p=attn_p,\n",
    "            proj_p=p\n",
    "        )\n",
    "        self.encoder_decoder_attn = EncoderDecoderAttention(\n",
    "            dim,\n",
    "            n_heads=n_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            attn_p=attn_p,\n",
    "            proj_p=p\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        hidden_features = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(\n",
    "            in_features=dim,\n",
    "            hidden_features=hidden_features,\n",
    "            out_features=dim,\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(dim, eps=1e-6)\n",
    "\n",
    "    def forward(self, x: Tensor, k: Tensor, v: Tensor,\n",
    "                mask_self_attn: Tensor = None, mask_cross_attn: Tensor = None) -> Tensor:\n",
    "        \"\"\"Run forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(batch_size, n_patches + 1, dim)`.\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(batch_size, n_patches + 1, dim)`.\n",
    "        \"\"\"\n",
    "        attn, _, _, _ = self.self_attn(x, mask_self_attn)\n",
    "        \n",
    "        attn_add_norm = self.norm1(attn + x)\n",
    "        attn, _, _, _ = self.encoder_decoder_attn(attn_add_norm, k, v, mask_cross_attn)\n",
    "        attn_add_norm = self.norm2(attn + x)\n",
    "        z = self.mlp(attn_add_norm)\n",
    "        out = self.norm3(z+attn_add_norm)\n",
    "        \n",
    "        return out\n",
    "\n",
    "decoder_block = DecoderBlock()\n",
    "decoded_tgt = decoder_block(tgt_pos_embed, k, v)\n",
    "print(decoded_tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "cf001610-23dc-4dfc-8df8-bcfa99bb727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 82])\n",
      "torch.Size([32, 82, 405])\n",
      "torch.Size([32, 82, 405])\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"The enzyme transformer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    embed_dim : int\n",
    "        Dimensionality of the token/patch embeddings.\n",
    "    encoder_depth : int\n",
    "        Number of blocks.\n",
    "    decoder_depth : int\n",
    "        Number of blocks.\n",
    "    n_heads : int\n",
    "        Number of attention heads.\n",
    "    mlp_ratio : float\n",
    "        Determines the hidden dimension of the `MLP` module.\n",
    "    qkv_bias : bool\n",
    "        If True then we include bias to the query, key and value projections.\n",
    "    p, attn_p : float\n",
    "        Dropout probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            src_vocab_size,\n",
    "            tgt_vocab_size,\n",
    "            embed_dim=512,\n",
    "            encoder_depth=8,\n",
    "            decoder_depth=8,\n",
    "            n_heads=8,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=True,\n",
    "            p=0.,\n",
    "            attn_p=0.,\n",
    "            src_masking=False,\n",
    "            tgt_masking=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_embedding = Embedding(vocab_size=src_vocab_size)\n",
    "        self.tgt_embedding = Embedding(vocab_size=tgt_vocab_size)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.pos_drop = nn.Dropout(p=p)\n",
    "\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [\n",
    "                EncoderBlock(\n",
    "                    dim=embed_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    p=p,\n",
    "                    attn_p=attn_p,\n",
    "                )\n",
    "                for _ in range(encoder_depth)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(\n",
    "                    dim=embed_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    p=p,\n",
    "                    attn_p=attn_p,\n",
    "                )\n",
    "                for _ in range(decoder_depth)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.src_masking = src_masking\n",
    "        self.tgt_masking = tgt_masking\n",
    "        \n",
    "        self.head = nn.Linear(embed_dim, tgt_vocab_size)\n",
    "        self.softmax = F.softmax \n",
    "    \n",
    "    def generate_mask(self, s1: int, s2: int) -> Tensor:\n",
    "        \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "        return torch.triu(torch.ones(s1, s2) * float('-inf'), diagonal=1)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"Run the forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(batch_size, in_chans, num_atoms, num_encoding_dimensions)`.\n",
    "        Returns\n",
    "        -------\n",
    "        logits : torch.Tensor\n",
    "            Logits over all the classes - `(batch_size, n_classes)`.\n",
    "        \"\"\"\n",
    "        if self.src_masking:\n",
    "            src_mask = self.generate_mask(src.size(1), src.size(1))\n",
    "        else:\n",
    "            src_mask = None\n",
    "        \n",
    "        if self.tgt_masking:\n",
    "            tgt_mask_self_attn = self.generate_mask(tgt.size(1), tgt.size(1))\n",
    "            tgt_mask_cross_attn = self.generate_mask(tgt.size(1), src.size(1))\n",
    "\n",
    "        else:\n",
    "            tgt_mask_self_attn = None\n",
    "            tgt_mask_cross_attn = None\n",
    "            \n",
    "        src_embed = self.src_embedding(src)\n",
    "        src = self.pos_encoding(src_embed)\n",
    "        src = self.pos_drop(src)\n",
    "\n",
    "        for block in self.encoder_blocks:\n",
    "            src, k, v = block(src, mask=src_mask)\n",
    "        \n",
    "        tgt_embed = self.tgt_embedding(tgt)\n",
    "        tgt = self.pos_encoding(tgt_embed)\n",
    "        tgt = self.pos_drop(tgt)\n",
    "        \n",
    "        for block in self.decoder_blocks:\n",
    "            tgt = block(tgt, k, v, \n",
    "                        mask_self_attn=tgt_mask_self_attn, \n",
    "                        mask_cross_attn=tgt_mask_cross_attn)\n",
    "\n",
    "        \n",
    "        out = self.head(tgt)\n",
    "        out = self.softmax(out, dim=-1)\n",
    "        out = out.permute(1,0,2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = Transformer(src_vocab_size=len(vocab), tgt_vocab_size=len(vocab))\n",
    "out = model(src, tgt)\n",
    "tgt_ohe = one_hot_encoder(tgt, len(vocab))\n",
    "print(tgt.shape)\n",
    "print(tgt_ohe.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbadf283-021d-4a9b-8d71-bcafc7f56825",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "61db1946-2f6c-432f-ab9a-0f71acc82959",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    embed_dim=512,\n",
    "    encoder_depth=2,\n",
    "    decoder_depth=2,\n",
    "    n_heads=8,\n",
    "    mlp_ratio=4.,\n",
    "    qkv_bias=True,\n",
    "    p=0.,\n",
    "    attn_p=0.,\n",
    "    src_masking=False,\n",
    "    tgt_masking=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1e433f44-f4de-4e67-ba44-564f9e81fa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0022, 0.0063, 0.0008,  ..., 0.0014, 0.0008, 0.0044],\n",
      "         [0.0047, 0.0026, 0.0010,  ..., 0.0008, 0.0011, 0.0017],\n",
      "         [0.0023, 0.0054, 0.0019,  ..., 0.0018, 0.0009, 0.0047],\n",
      "         ...,\n",
      "         [0.0076, 0.0030, 0.0018,  ..., 0.0029, 0.0026, 0.0041],\n",
      "         [0.0066, 0.0028, 0.0021,  ..., 0.0036, 0.0018, 0.0060],\n",
      "         [0.0080, 0.0036, 0.0014,  ..., 0.0050, 0.0026, 0.0041]],\n",
      "\n",
      "        [[0.0018, 0.0034, 0.0009,  ..., 0.0008, 0.0005, 0.0066],\n",
      "         [0.0044, 0.0029, 0.0008,  ..., 0.0010, 0.0012, 0.0027],\n",
      "         [0.0028, 0.0026, 0.0017,  ..., 0.0010, 0.0011, 0.0055],\n",
      "         ...,\n",
      "         [0.0066, 0.0020, 0.0021,  ..., 0.0029, 0.0025, 0.0051],\n",
      "         [0.0061, 0.0029, 0.0022,  ..., 0.0028, 0.0027, 0.0043],\n",
      "         [0.0070, 0.0035, 0.0021,  ..., 0.0032, 0.0025, 0.0056]],\n",
      "\n",
      "        [[0.0019, 0.0036, 0.0008,  ..., 0.0014, 0.0014, 0.0061],\n",
      "         [0.0012, 0.0036, 0.0017,  ..., 0.0020, 0.0037, 0.0101],\n",
      "         [0.0016, 0.0019, 0.0018,  ..., 0.0019, 0.0036, 0.0133],\n",
      "         ...,\n",
      "         [0.0058, 0.0021, 0.0025,  ..., 0.0029, 0.0022, 0.0056],\n",
      "         [0.0067, 0.0030, 0.0016,  ..., 0.0025, 0.0022, 0.0087],\n",
      "         [0.0071, 0.0030, 0.0017,  ..., 0.0023, 0.0033, 0.0068]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0013, 0.0031, 0.0014,  ..., 0.0010, 0.0007, 0.0040],\n",
      "         [0.0014, 0.0019, 0.0030,  ..., 0.0018, 0.0021, 0.0079],\n",
      "         [0.0015, 0.0026, 0.0033,  ..., 0.0020, 0.0033, 0.0080],\n",
      "         ...,\n",
      "         [0.0055, 0.0028, 0.0029,  ..., 0.0019, 0.0019, 0.0031],\n",
      "         [0.0043, 0.0015, 0.0028,  ..., 0.0028, 0.0019, 0.0035],\n",
      "         [0.0047, 0.0028, 0.0029,  ..., 0.0017, 0.0018, 0.0037]],\n",
      "\n",
      "        [[0.0015, 0.0023, 0.0014,  ..., 0.0006, 0.0008, 0.0037],\n",
      "         [0.0012, 0.0021, 0.0036,  ..., 0.0021, 0.0027, 0.0087],\n",
      "         [0.0043, 0.0018, 0.0027,  ..., 0.0038, 0.0003, 0.0031],\n",
      "         ...,\n",
      "         [0.0069, 0.0019, 0.0046,  ..., 0.0030, 0.0025, 0.0052],\n",
      "         [0.0046, 0.0017, 0.0029,  ..., 0.0026, 0.0017, 0.0043],\n",
      "         [0.0065, 0.0022, 0.0036,  ..., 0.0030, 0.0017, 0.0056]],\n",
      "\n",
      "        [[0.0012, 0.0028, 0.0010,  ..., 0.0011, 0.0006, 0.0047],\n",
      "         [0.0017, 0.0014, 0.0031,  ..., 0.0017, 0.0034, 0.0084],\n",
      "         [0.0016, 0.0014, 0.0021,  ..., 0.0020, 0.0029, 0.0079],\n",
      "         ...,\n",
      "         [0.0049, 0.0018, 0.0035,  ..., 0.0020, 0.0021, 0.0064],\n",
      "         [0.0040, 0.0018, 0.0044,  ..., 0.0033, 0.0019, 0.0026],\n",
      "         [0.0047, 0.0019, 0.0030,  ..., 0.0028, 0.0023, 0.0052]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(1.0000)\n",
      "tensor([[[0.0016, 0.0045, 0.0011,  ..., 0.0014, 0.0010, 0.0039],\n",
      "         [0.0022, 0.0030, 0.0019,  ..., 0.0027, 0.0050, 0.0119],\n",
      "         [0.0019, 0.0029, 0.0016,  ..., 0.0023, 0.0026, 0.0080],\n",
      "         ...,\n",
      "         [0.0051, 0.0034, 0.0014,  ..., 0.0032, 0.0018, 0.0053],\n",
      "         [0.0050, 0.0049, 0.0027,  ..., 0.0036, 0.0019, 0.0050],\n",
      "         [0.0057, 0.0039, 0.0017,  ..., 0.0032, 0.0016, 0.0050]],\n",
      "\n",
      "        [[0.0017, 0.0054, 0.0007,  ..., 0.0010, 0.0012, 0.0051],\n",
      "         [0.0014, 0.0037, 0.0020,  ..., 0.0027, 0.0041, 0.0089],\n",
      "         [0.0051, 0.0030, 0.0013,  ..., 0.0048, 0.0004, 0.0039],\n",
      "         ...,\n",
      "         [0.0078, 0.0029, 0.0019,  ..., 0.0031, 0.0037, 0.0050],\n",
      "         [0.0068, 0.0032, 0.0016,  ..., 0.0040, 0.0020, 0.0056],\n",
      "         [0.0059, 0.0022, 0.0030,  ..., 0.0036, 0.0026, 0.0067]],\n",
      "\n",
      "        [[0.0012, 0.0058, 0.0008,  ..., 0.0015, 0.0016, 0.0079],\n",
      "         [0.0014, 0.0031, 0.0019,  ..., 0.0017, 0.0041, 0.0108],\n",
      "         [0.0014, 0.0021, 0.0019,  ..., 0.0020, 0.0047, 0.0114],\n",
      "         ...,\n",
      "         [0.0062, 0.0023, 0.0013,  ..., 0.0035, 0.0021, 0.0038],\n",
      "         [0.0045, 0.0033, 0.0043,  ..., 0.0020, 0.0030, 0.0057],\n",
      "         [0.0040, 0.0028, 0.0020,  ..., 0.0021, 0.0025, 0.0067]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0014, 0.0051, 0.0013,  ..., 0.0008, 0.0010, 0.0060],\n",
      "         [0.0012, 0.0020, 0.0028,  ..., 0.0021, 0.0032, 0.0059],\n",
      "         [0.0019, 0.0019, 0.0019,  ..., 0.0012, 0.0014, 0.0023],\n",
      "         ...,\n",
      "         [0.0048, 0.0020, 0.0031,  ..., 0.0020, 0.0014, 0.0042],\n",
      "         [0.0068, 0.0026, 0.0040,  ..., 0.0018, 0.0019, 0.0038],\n",
      "         [0.0065, 0.0022, 0.0041,  ..., 0.0024, 0.0019, 0.0048]],\n",
      "\n",
      "        [[0.0016, 0.0048, 0.0017,  ..., 0.0009, 0.0007, 0.0063],\n",
      "         [0.0013, 0.0021, 0.0028,  ..., 0.0022, 0.0036, 0.0075],\n",
      "         [0.0018, 0.0020, 0.0026,  ..., 0.0017, 0.0018, 0.0021],\n",
      "         ...,\n",
      "         [0.0035, 0.0030, 0.0035,  ..., 0.0028, 0.0022, 0.0036],\n",
      "         [0.0045, 0.0028, 0.0029,  ..., 0.0020, 0.0018, 0.0035],\n",
      "         [0.0056, 0.0024, 0.0030,  ..., 0.0018, 0.0019, 0.0036]],\n",
      "\n",
      "        [[0.0012, 0.0039, 0.0013,  ..., 0.0010, 0.0011, 0.0053],\n",
      "         [0.0012, 0.0019, 0.0028,  ..., 0.0014, 0.0028, 0.0087],\n",
      "         [0.0014, 0.0019, 0.0040,  ..., 0.0018, 0.0027, 0.0095],\n",
      "         ...,\n",
      "         [0.0045, 0.0022, 0.0034,  ..., 0.0026, 0.0019, 0.0042],\n",
      "         [0.0048, 0.0023, 0.0031,  ..., 0.0033, 0.0022, 0.0052],\n",
      "         [0.0039, 0.0021, 0.0049,  ..., 0.0030, 0.0022, 0.0069]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(0.9999)\n",
      "tensor([[[0.0020, 0.0048, 0.0009,  ..., 0.0015, 0.0009, 0.0071],\n",
      "         [0.0015, 0.0026, 0.0020,  ..., 0.0021, 0.0034, 0.0098],\n",
      "         [0.0020, 0.0033, 0.0018,  ..., 0.0018, 0.0026, 0.0088],\n",
      "         ...,\n",
      "         [0.0052, 0.0045, 0.0018,  ..., 0.0038, 0.0016, 0.0051],\n",
      "         [0.0052, 0.0053, 0.0019,  ..., 0.0050, 0.0023, 0.0053],\n",
      "         [0.0071, 0.0066, 0.0030,  ..., 0.0040, 0.0019, 0.0047]],\n",
      "\n",
      "        [[0.0012, 0.0048, 0.0005,  ..., 0.0018, 0.0013, 0.0035],\n",
      "         [0.0050, 0.0023, 0.0011,  ..., 0.0012, 0.0013, 0.0021],\n",
      "         [0.0027, 0.0035, 0.0019,  ..., 0.0024, 0.0018, 0.0052],\n",
      "         ...,\n",
      "         [0.0068, 0.0043, 0.0023,  ..., 0.0044, 0.0020, 0.0049],\n",
      "         [0.0065, 0.0050, 0.0017,  ..., 0.0045, 0.0025, 0.0041],\n",
      "         [0.0066, 0.0042, 0.0022,  ..., 0.0032, 0.0022, 0.0054]],\n",
      "\n",
      "        [[0.0010, 0.0041, 0.0009,  ..., 0.0013, 0.0015, 0.0048],\n",
      "         [0.0011, 0.0028, 0.0020,  ..., 0.0025, 0.0030, 0.0078],\n",
      "         [0.0037, 0.0024, 0.0019,  ..., 0.0009, 0.0020, 0.0027],\n",
      "         ...,\n",
      "         [0.0045, 0.0022, 0.0018,  ..., 0.0034, 0.0024, 0.0078],\n",
      "         [0.0063, 0.0042, 0.0021,  ..., 0.0037, 0.0020, 0.0058],\n",
      "         [0.0059, 0.0038, 0.0022,  ..., 0.0024, 0.0023, 0.0057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0010, 0.0029, 0.0009,  ..., 0.0009, 0.0010, 0.0031],\n",
      "         [0.0032, 0.0027, 0.0021,  ..., 0.0010, 0.0013, 0.0021],\n",
      "         [0.0028, 0.0022, 0.0027,  ..., 0.0014, 0.0010, 0.0038],\n",
      "         ...,\n",
      "         [0.0042, 0.0029, 0.0032,  ..., 0.0027, 0.0018, 0.0035],\n",
      "         [0.0049, 0.0031, 0.0036,  ..., 0.0024, 0.0021, 0.0035],\n",
      "         [0.0052, 0.0029, 0.0029,  ..., 0.0020, 0.0017, 0.0031]],\n",
      "\n",
      "        [[0.0013, 0.0053, 0.0021,  ..., 0.0011, 0.0009, 0.0051],\n",
      "         [0.0014, 0.0018, 0.0037,  ..., 0.0020, 0.0035, 0.0087],\n",
      "         [0.0030, 0.0018, 0.0020,  ..., 0.0008, 0.0011, 0.0019],\n",
      "         ...,\n",
      "         [0.0045, 0.0028, 0.0032,  ..., 0.0023, 0.0017, 0.0041],\n",
      "         [0.0041, 0.0030, 0.0034,  ..., 0.0020, 0.0018, 0.0041],\n",
      "         [0.0043, 0.0033, 0.0044,  ..., 0.0022, 0.0025, 0.0043]],\n",
      "\n",
      "        [[0.0011, 0.0057, 0.0018,  ..., 0.0015, 0.0013, 0.0048],\n",
      "         [0.0010, 0.0022, 0.0028,  ..., 0.0018, 0.0042, 0.0054],\n",
      "         [0.0011, 0.0013, 0.0035,  ..., 0.0019, 0.0025, 0.0079],\n",
      "         ...,\n",
      "         [0.0056, 0.0023, 0.0044,  ..., 0.0025, 0.0025, 0.0062],\n",
      "         [0.0044, 0.0030, 0.0027,  ..., 0.0016, 0.0019, 0.0046],\n",
      "         [0.0036, 0.0025, 0.0030,  ..., 0.0026, 0.0021, 0.0052]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(0.9458)\n",
      "tensor([[[0.0021, 0.0049, 0.0008,  ..., 0.0017, 0.0007, 0.0047],\n",
      "         [0.0027, 0.0035, 0.0015,  ..., 0.0026, 0.0032, 0.0062],\n",
      "         [0.0019, 0.0035, 0.0014,  ..., 0.0025, 0.0025, 0.0063],\n",
      "         ...,\n",
      "         [0.0083, 0.0048, 0.0021,  ..., 0.0033, 0.0017, 0.0054],\n",
      "         [0.0069, 0.0043, 0.0021,  ..., 0.0030, 0.0021, 0.0055],\n",
      "         [0.0065, 0.0051, 0.0011,  ..., 0.0036, 0.0024, 0.0051]],\n",
      "\n",
      "        [[0.0017, 0.0037, 0.0006,  ..., 0.0018, 0.0011, 0.0051],\n",
      "         [0.0017, 0.0021, 0.0017,  ..., 0.0032, 0.0034, 0.0094],\n",
      "         [0.0016, 0.0030, 0.0012,  ..., 0.0020, 0.0026, 0.0029],\n",
      "         ...,\n",
      "         [0.0051, 0.0028, 0.0026,  ..., 0.0039, 0.0024, 0.0050],\n",
      "         [0.0063, 0.0041, 0.0023,  ..., 0.0035, 0.0024, 0.0056],\n",
      "         [0.0076, 0.0039, 0.0020,  ..., 0.0043, 0.0017, 0.0072]],\n",
      "\n",
      "        [[0.0017, 0.0038, 0.0009,  ..., 0.0011, 0.0015, 0.0048],\n",
      "         [0.0012, 0.0029, 0.0023,  ..., 0.0027, 0.0035, 0.0074],\n",
      "         [0.0016, 0.0020, 0.0016,  ..., 0.0028, 0.0027, 0.0069],\n",
      "         ...,\n",
      "         [0.0060, 0.0044, 0.0025,  ..., 0.0028, 0.0025, 0.0052],\n",
      "         [0.0082, 0.0032, 0.0018,  ..., 0.0031, 0.0030, 0.0076],\n",
      "         [0.0062, 0.0040, 0.0025,  ..., 0.0035, 0.0025, 0.0047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0012, 0.0059, 0.0012,  ..., 0.0015, 0.0008, 0.0032],\n",
      "         [0.0018, 0.0024, 0.0027,  ..., 0.0019, 0.0029, 0.0058],\n",
      "         [0.0013, 0.0026, 0.0032,  ..., 0.0017, 0.0023, 0.0077],\n",
      "         ...,\n",
      "         [0.0044, 0.0024, 0.0047,  ..., 0.0028, 0.0014, 0.0036],\n",
      "         [0.0037, 0.0031, 0.0044,  ..., 0.0024, 0.0016, 0.0048],\n",
      "         [0.0052, 0.0042, 0.0038,  ..., 0.0028, 0.0018, 0.0033]],\n",
      "\n",
      "        [[0.0015, 0.0024, 0.0015,  ..., 0.0007, 0.0009, 0.0040],\n",
      "         [0.0014, 0.0016, 0.0031,  ..., 0.0024, 0.0022, 0.0058],\n",
      "         [0.0031, 0.0020, 0.0027,  ..., 0.0009, 0.0010, 0.0014],\n",
      "         ...,\n",
      "         [0.0041, 0.0030, 0.0031,  ..., 0.0027, 0.0017, 0.0028],\n",
      "         [0.0042, 0.0027, 0.0035,  ..., 0.0026, 0.0026, 0.0044],\n",
      "         [0.0045, 0.0023, 0.0052,  ..., 0.0028, 0.0019, 0.0035]],\n",
      "\n",
      "        [[0.0013, 0.0049, 0.0019,  ..., 0.0012, 0.0011, 0.0049],\n",
      "         [0.0015, 0.0015, 0.0032,  ..., 0.0017, 0.0031, 0.0080],\n",
      "         [0.0016, 0.0016, 0.0027,  ..., 0.0026, 0.0025, 0.0090],\n",
      "         ...,\n",
      "         [0.0051, 0.0029, 0.0027,  ..., 0.0027, 0.0024, 0.0049],\n",
      "         [0.0036, 0.0029, 0.0026,  ..., 0.0029, 0.0030, 0.0040],\n",
      "         [0.0067, 0.0019, 0.0037,  ..., 0.0027, 0.0027, 0.0046]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(1.1232)\n",
      "tensor([[[0.0020, 0.0042, 0.0008,  ..., 0.0017, 0.0011, 0.0046],\n",
      "         [0.0011, 0.0031, 0.0014,  ..., 0.0031, 0.0033, 0.0063],\n",
      "         [0.0018, 0.0030, 0.0013,  ..., 0.0027, 0.0021, 0.0025],\n",
      "         ...,\n",
      "         [0.0050, 0.0059, 0.0025,  ..., 0.0037, 0.0020, 0.0046],\n",
      "         [0.0097, 0.0071, 0.0016,  ..., 0.0043, 0.0018, 0.0048],\n",
      "         [0.0061, 0.0064, 0.0020,  ..., 0.0031, 0.0014, 0.0044]],\n",
      "\n",
      "        [[0.0015, 0.0051, 0.0012,  ..., 0.0018, 0.0011, 0.0066],\n",
      "         [0.0018, 0.0024, 0.0020,  ..., 0.0025, 0.0041, 0.0087],\n",
      "         [0.0038, 0.0035, 0.0014,  ..., 0.0011, 0.0013, 0.0031],\n",
      "         ...,\n",
      "         [0.0035, 0.0043, 0.0023,  ..., 0.0041, 0.0020, 0.0044],\n",
      "         [0.0057, 0.0061, 0.0019,  ..., 0.0047, 0.0034, 0.0058],\n",
      "         [0.0057, 0.0044, 0.0016,  ..., 0.0044, 0.0025, 0.0051]],\n",
      "\n",
      "        [[0.0013, 0.0054, 0.0012,  ..., 0.0017, 0.0012, 0.0061],\n",
      "         [0.0021, 0.0021, 0.0021,  ..., 0.0020, 0.0041, 0.0083],\n",
      "         [0.0016, 0.0025, 0.0022,  ..., 0.0024, 0.0047, 0.0073],\n",
      "         ...,\n",
      "         [0.0045, 0.0057, 0.0022,  ..., 0.0030, 0.0022, 0.0052],\n",
      "         [0.0061, 0.0051, 0.0023,  ..., 0.0031, 0.0028, 0.0060],\n",
      "         [0.0042, 0.0050, 0.0022,  ..., 0.0026, 0.0020, 0.0056]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0012, 0.0031, 0.0016,  ..., 0.0010, 0.0010, 0.0038],\n",
      "         [0.0013, 0.0024, 0.0031,  ..., 0.0015, 0.0034, 0.0060],\n",
      "         [0.0025, 0.0020, 0.0024,  ..., 0.0010, 0.0012, 0.0017],\n",
      "         ...,\n",
      "         [0.0049, 0.0043, 0.0040,  ..., 0.0027, 0.0019, 0.0032],\n",
      "         [0.0047, 0.0030, 0.0030,  ..., 0.0028, 0.0018, 0.0036],\n",
      "         [0.0047, 0.0038, 0.0041,  ..., 0.0027, 0.0016, 0.0036]],\n",
      "\n",
      "        [[0.0017, 0.0028, 0.0013,  ..., 0.0011, 0.0010, 0.0048],\n",
      "         [0.0020, 0.0015, 0.0035,  ..., 0.0017, 0.0042, 0.0062],\n",
      "         [0.0048, 0.0017, 0.0023,  ..., 0.0029, 0.0005, 0.0031],\n",
      "         ...,\n",
      "         [0.0045, 0.0034, 0.0033,  ..., 0.0024, 0.0016, 0.0038],\n",
      "         [0.0044, 0.0033, 0.0038,  ..., 0.0023, 0.0019, 0.0043],\n",
      "         [0.0049, 0.0030, 0.0035,  ..., 0.0028, 0.0017, 0.0048]],\n",
      "\n",
      "        [[0.0013, 0.0035, 0.0013,  ..., 0.0013, 0.0010, 0.0044],\n",
      "         [0.0013, 0.0015, 0.0035,  ..., 0.0020, 0.0035, 0.0061],\n",
      "         [0.0014, 0.0019, 0.0026,  ..., 0.0015, 0.0021, 0.0026],\n",
      "         ...,\n",
      "         [0.0052, 0.0054, 0.0035,  ..., 0.0029, 0.0025, 0.0033],\n",
      "         [0.0046, 0.0032, 0.0026,  ..., 0.0036, 0.0022, 0.0045],\n",
      "         [0.0034, 0.0034, 0.0047,  ..., 0.0024, 0.0019, 0.0046]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(0.8523)\n",
      "tensor([[[0.0016, 0.0051, 0.0013,  ..., 0.0015, 0.0011, 0.0062],\n",
      "         [0.0021, 0.0029, 0.0019,  ..., 0.0026, 0.0035, 0.0079],\n",
      "         [0.0015, 0.0033, 0.0018,  ..., 0.0024, 0.0018, 0.0024],\n",
      "         ...,\n",
      "         [0.0050, 0.0056, 0.0023,  ..., 0.0039, 0.0020, 0.0036],\n",
      "         [0.0054, 0.0088, 0.0018,  ..., 0.0041, 0.0021, 0.0064],\n",
      "         [0.0062, 0.0064, 0.0020,  ..., 0.0045, 0.0025, 0.0052]],\n",
      "\n",
      "        [[0.0017, 0.0055, 0.0012,  ..., 0.0013, 0.0014, 0.0049],\n",
      "         [0.0015, 0.0027, 0.0021,  ..., 0.0019, 0.0038, 0.0076],\n",
      "         [0.0016, 0.0030, 0.0021,  ..., 0.0025, 0.0031, 0.0075],\n",
      "         ...,\n",
      "         [0.0049, 0.0046, 0.0016,  ..., 0.0033, 0.0026, 0.0054],\n",
      "         [0.0057, 0.0060, 0.0013,  ..., 0.0028, 0.0026, 0.0049],\n",
      "         [0.0048, 0.0053, 0.0015,  ..., 0.0036, 0.0028, 0.0042]],\n",
      "\n",
      "        [[0.0020, 0.0039, 0.0011,  ..., 0.0016, 0.0012, 0.0043],\n",
      "         [0.0018, 0.0032, 0.0024,  ..., 0.0025, 0.0045, 0.0074],\n",
      "         [0.0013, 0.0025, 0.0021,  ..., 0.0018, 0.0044, 0.0079],\n",
      "         ...,\n",
      "         [0.0038, 0.0056, 0.0018,  ..., 0.0041, 0.0024, 0.0054],\n",
      "         [0.0043, 0.0054, 0.0022,  ..., 0.0031, 0.0026, 0.0053],\n",
      "         [0.0059, 0.0059, 0.0020,  ..., 0.0032, 0.0028, 0.0036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0015, 0.0034, 0.0016,  ..., 0.0014, 0.0012, 0.0028],\n",
      "         [0.0031, 0.0028, 0.0023,  ..., 0.0029, 0.0005, 0.0026],\n",
      "         [0.0020, 0.0019, 0.0025,  ..., 0.0015, 0.0017, 0.0019],\n",
      "         ...,\n",
      "         [0.0045, 0.0036, 0.0031,  ..., 0.0027, 0.0013, 0.0044],\n",
      "         [0.0067, 0.0045, 0.0034,  ..., 0.0025, 0.0022, 0.0034],\n",
      "         [0.0052, 0.0034, 0.0044,  ..., 0.0024, 0.0018, 0.0037]],\n",
      "\n",
      "        [[0.0017, 0.0019, 0.0015,  ..., 0.0016, 0.0009, 0.0029],\n",
      "         [0.0025, 0.0021, 0.0030,  ..., 0.0011, 0.0014, 0.0012],\n",
      "         [0.0028, 0.0022, 0.0032,  ..., 0.0017, 0.0012, 0.0030],\n",
      "         ...,\n",
      "         [0.0047, 0.0044, 0.0031,  ..., 0.0026, 0.0015, 0.0033],\n",
      "         [0.0041, 0.0029, 0.0037,  ..., 0.0029, 0.0018, 0.0039],\n",
      "         [0.0041, 0.0045, 0.0043,  ..., 0.0026, 0.0025, 0.0040]],\n",
      "\n",
      "        [[0.0014, 0.0037, 0.0013,  ..., 0.0013, 0.0013, 0.0041],\n",
      "         [0.0014, 0.0020, 0.0027,  ..., 0.0023, 0.0038, 0.0074],\n",
      "         [0.0018, 0.0016, 0.0035,  ..., 0.0017, 0.0026, 0.0075],\n",
      "         ...,\n",
      "         [0.0049, 0.0059, 0.0028,  ..., 0.0024, 0.0021, 0.0041],\n",
      "         [0.0040, 0.0042, 0.0034,  ..., 0.0033, 0.0020, 0.0039],\n",
      "         [0.0056, 0.0039, 0.0033,  ..., 0.0028, 0.0021, 0.0046]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(1.0407)\n",
      "tensor([[[0.0017, 0.0056, 0.0011,  ..., 0.0019, 0.0012, 0.0047],\n",
      "         [0.0014, 0.0036, 0.0014,  ..., 0.0028, 0.0033, 0.0076],\n",
      "         [0.0026, 0.0040, 0.0022,  ..., 0.0022, 0.0011, 0.0034],\n",
      "         ...,\n",
      "         [0.0057, 0.0064, 0.0016,  ..., 0.0033, 0.0030, 0.0044],\n",
      "         [0.0056, 0.0080, 0.0020,  ..., 0.0026, 0.0028, 0.0055],\n",
      "         [0.0057, 0.0106, 0.0017,  ..., 0.0033, 0.0022, 0.0048]],\n",
      "\n",
      "        [[0.0019, 0.0039, 0.0009,  ..., 0.0015, 0.0013, 0.0051],\n",
      "         [0.0016, 0.0031, 0.0024,  ..., 0.0025, 0.0035, 0.0083],\n",
      "         [0.0037, 0.0034, 0.0018,  ..., 0.0014, 0.0018, 0.0019],\n",
      "         ...,\n",
      "         [0.0052, 0.0054, 0.0014,  ..., 0.0035, 0.0033, 0.0056],\n",
      "         [0.0048, 0.0066, 0.0022,  ..., 0.0030, 0.0034, 0.0049],\n",
      "         [0.0055, 0.0060, 0.0019,  ..., 0.0035, 0.0030, 0.0055]],\n",
      "\n",
      "        [[0.0015, 0.0042, 0.0012,  ..., 0.0017, 0.0013, 0.0045],\n",
      "         [0.0015, 0.0038, 0.0015,  ..., 0.0027, 0.0045, 0.0081],\n",
      "         [0.0027, 0.0021, 0.0016,  ..., 0.0011, 0.0020, 0.0019],\n",
      "         ...,\n",
      "         [0.0069, 0.0076, 0.0023,  ..., 0.0042, 0.0038, 0.0051],\n",
      "         [0.0059, 0.0079, 0.0019,  ..., 0.0032, 0.0023, 0.0052],\n",
      "         [0.0069, 0.0068, 0.0019,  ..., 0.0034, 0.0032, 0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0018, 0.0035, 0.0018,  ..., 0.0012, 0.0011, 0.0029],\n",
      "         [0.0012, 0.0019, 0.0037,  ..., 0.0021, 0.0036, 0.0078],\n",
      "         [0.0038, 0.0024, 0.0027,  ..., 0.0039, 0.0006, 0.0025],\n",
      "         ...,\n",
      "         [0.0047, 0.0046, 0.0025,  ..., 0.0022, 0.0017, 0.0032],\n",
      "         [0.0040, 0.0060, 0.0028,  ..., 0.0022, 0.0018, 0.0038],\n",
      "         [0.0048, 0.0049, 0.0034,  ..., 0.0030, 0.0013, 0.0030]],\n",
      "\n",
      "        [[0.0016, 0.0031, 0.0018,  ..., 0.0011, 0.0010, 0.0031],\n",
      "         [0.0017, 0.0018, 0.0039,  ..., 0.0020, 0.0027, 0.0080],\n",
      "         [0.0019, 0.0018, 0.0032,  ..., 0.0015, 0.0024, 0.0022],\n",
      "         ...,\n",
      "         [0.0053, 0.0058, 0.0026,  ..., 0.0036, 0.0026, 0.0034],\n",
      "         [0.0038, 0.0047, 0.0033,  ..., 0.0027, 0.0022, 0.0035],\n",
      "         [0.0045, 0.0042, 0.0031,  ..., 0.0031, 0.0020, 0.0028]],\n",
      "\n",
      "        [[0.0013, 0.0027, 0.0018,  ..., 0.0012, 0.0010, 0.0038],\n",
      "         [0.0022, 0.0024, 0.0034,  ..., 0.0021, 0.0027, 0.0074],\n",
      "         [0.0018, 0.0020, 0.0025,  ..., 0.0012, 0.0018, 0.0034],\n",
      "         ...,\n",
      "         [0.0044, 0.0054, 0.0029,  ..., 0.0038, 0.0017, 0.0045],\n",
      "         [0.0036, 0.0060, 0.0033,  ..., 0.0025, 0.0022, 0.0039],\n",
      "         [0.0041, 0.0054, 0.0032,  ..., 0.0026, 0.0020, 0.0054]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(0.9189)\n",
      "tensor([[[0.0020, 0.0038, 0.0008,  ..., 0.0016, 0.0010, 0.0028],\n",
      "         [0.0018, 0.0033, 0.0025,  ..., 0.0027, 0.0031, 0.0065],\n",
      "         [0.0035, 0.0030, 0.0019,  ..., 0.0018, 0.0017, 0.0039],\n",
      "         ...,\n",
      "         [0.0017, 0.0042, 0.0023,  ..., 0.0029, 0.0034, 0.0068],\n",
      "         [0.0018, 0.0030, 0.0018,  ..., 0.0028, 0.0047, 0.0048],\n",
      "         [0.0035, 0.0040, 0.0014,  ..., 0.0032, 0.0018, 0.0023]],\n",
      "\n",
      "        [[0.0017, 0.0040, 0.0009,  ..., 0.0017, 0.0014, 0.0038],\n",
      "         [0.0026, 0.0022, 0.0017,  ..., 0.0032, 0.0042, 0.0037],\n",
      "         [0.0023, 0.0018, 0.0013,  ..., 0.0023, 0.0021, 0.0019],\n",
      "         ...,\n",
      "         [0.0051, 0.0097, 0.0017,  ..., 0.0040, 0.0022, 0.0039],\n",
      "         [0.0054, 0.0072, 0.0017,  ..., 0.0037, 0.0028, 0.0041],\n",
      "         [0.0069, 0.0096, 0.0024,  ..., 0.0051, 0.0032, 0.0057]],\n",
      "\n",
      "        [[0.0022, 0.0035, 0.0009,  ..., 0.0013, 0.0013, 0.0038],\n",
      "         [0.0017, 0.0027, 0.0023,  ..., 0.0029, 0.0043, 0.0070],\n",
      "         [0.0014, 0.0028, 0.0028,  ..., 0.0018, 0.0034, 0.0075],\n",
      "         ...,\n",
      "         [0.0046, 0.0084, 0.0020,  ..., 0.0029, 0.0033, 0.0059],\n",
      "         [0.0055, 0.0073, 0.0025,  ..., 0.0037, 0.0026, 0.0050],\n",
      "         [0.0060, 0.0079, 0.0021,  ..., 0.0040, 0.0030, 0.0046]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0017, 0.0027, 0.0018,  ..., 0.0015, 0.0013, 0.0026],\n",
      "         [0.0012, 0.0020, 0.0030,  ..., 0.0020, 0.0029, 0.0052],\n",
      "         [0.0016, 0.0019, 0.0028,  ..., 0.0024, 0.0028, 0.0048],\n",
      "         ...,\n",
      "         [0.0041, 0.0058, 0.0031,  ..., 0.0027, 0.0016, 0.0032],\n",
      "         [0.0031, 0.0065, 0.0025,  ..., 0.0027, 0.0021, 0.0032],\n",
      "         [0.0058, 0.0088, 0.0029,  ..., 0.0033, 0.0017, 0.0029]],\n",
      "\n",
      "        [[0.0014, 0.0037, 0.0017,  ..., 0.0013, 0.0013, 0.0038],\n",
      "         [0.0013, 0.0025, 0.0040,  ..., 0.0021, 0.0032, 0.0064],\n",
      "         [0.0014, 0.0024, 0.0044,  ..., 0.0020, 0.0033, 0.0058],\n",
      "         ...,\n",
      "         [0.0036, 0.0044, 0.0030,  ..., 0.0024, 0.0018, 0.0031],\n",
      "         [0.0045, 0.0058, 0.0035,  ..., 0.0021, 0.0024, 0.0037],\n",
      "         [0.0044, 0.0054, 0.0036,  ..., 0.0026, 0.0022, 0.0038]],\n",
      "\n",
      "        [[0.0016, 0.0036, 0.0019,  ..., 0.0014, 0.0012, 0.0032],\n",
      "         [0.0015, 0.0021, 0.0032,  ..., 0.0026, 0.0035, 0.0066],\n",
      "         [0.0018, 0.0023, 0.0032,  ..., 0.0021, 0.0046, 0.0070],\n",
      "         ...,\n",
      "         [0.0036, 0.0052, 0.0029,  ..., 0.0029, 0.0023, 0.0046],\n",
      "         [0.0043, 0.0053, 0.0026,  ..., 0.0042, 0.0021, 0.0037],\n",
      "         [0.0047, 0.0055, 0.0026,  ..., 0.0031, 0.0025, 0.0039]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor(0.9729)\n",
      "tensor([[[0.0017, 0.0030, 0.0009,  ..., 0.0017, 0.0014, 0.0036],\n",
      "         [0.0021, 0.0039, 0.0018,  ..., 0.0027, 0.0034, 0.0052],\n",
      "         [0.0026, 0.0026, 0.0015,  ..., 0.0011, 0.0017, 0.0031],\n",
      "         ...,\n",
      "         [0.0058, 0.0103, 0.0015,  ..., 0.0042, 0.0027, 0.0045],\n",
      "         [0.0065, 0.0112, 0.0017,  ..., 0.0040, 0.0020, 0.0037],\n",
      "         [0.0055, 0.0096, 0.0014,  ..., 0.0037, 0.0019, 0.0050]],\n",
      "\n",
      "        [[0.0019, 0.0054, 0.0011,  ..., 0.0018, 0.0014, 0.0045],\n",
      "         [0.0022, 0.0026, 0.0024,  ..., 0.0028, 0.0042, 0.0065],\n",
      "         [0.0042, 0.0028, 0.0013,  ..., 0.0042, 0.0008, 0.0029],\n",
      "         ...,\n",
      "         [0.0061, 0.0113, 0.0015,  ..., 0.0040, 0.0022, 0.0062],\n",
      "         [0.0056, 0.0084, 0.0019,  ..., 0.0035, 0.0028, 0.0054],\n",
      "         [0.0052, 0.0097, 0.0023,  ..., 0.0034, 0.0032, 0.0050]],\n",
      "\n",
      "        [[0.0022, 0.0050, 0.0012,  ..., 0.0012, 0.0015, 0.0050],\n",
      "         [0.0017, 0.0027, 0.0026,  ..., 0.0026, 0.0041, 0.0084],\n",
      "         [0.0038, 0.0029, 0.0019,  ..., 0.0012, 0.0022, 0.0027],\n",
      "         ...,\n",
      "         [0.0056, 0.0076, 0.0016,  ..., 0.0034, 0.0031, 0.0060],\n",
      "         [0.0048, 0.0085, 0.0022,  ..., 0.0039, 0.0032, 0.0056],\n",
      "         [0.0051, 0.0072, 0.0016,  ..., 0.0047, 0.0033, 0.0046]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0018, 0.0031, 0.0020,  ..., 0.0012, 0.0015, 0.0037],\n",
      "         [0.0029, 0.0013, 0.0021,  ..., 0.0012, 0.0014, 0.0049],\n",
      "         [0.0021, 0.0021, 0.0024,  ..., 0.0017, 0.0021, 0.0023],\n",
      "         ...,\n",
      "         [0.0036, 0.0065, 0.0032,  ..., 0.0035, 0.0023, 0.0039],\n",
      "         [0.0039, 0.0068, 0.0029,  ..., 0.0026, 0.0019, 0.0026],\n",
      "         [0.0044, 0.0050, 0.0024,  ..., 0.0020, 0.0016, 0.0029]],\n",
      "\n",
      "        [[0.0015, 0.0027, 0.0018,  ..., 0.0012, 0.0011, 0.0029],\n",
      "         [0.0015, 0.0025, 0.0039,  ..., 0.0021, 0.0030, 0.0058],\n",
      "         [0.0012, 0.0024, 0.0032,  ..., 0.0022, 0.0024, 0.0040],\n",
      "         ...,\n",
      "         [0.0038, 0.0063, 0.0031,  ..., 0.0027, 0.0024, 0.0032],\n",
      "         [0.0037, 0.0078, 0.0033,  ..., 0.0024, 0.0021, 0.0040],\n",
      "         [0.0033, 0.0059, 0.0028,  ..., 0.0027, 0.0021, 0.0027]],\n",
      "\n",
      "        [[0.0014, 0.0032, 0.0016,  ..., 0.0010, 0.0013, 0.0034],\n",
      "         [0.0028, 0.0027, 0.0029,  ..., 0.0013, 0.0015, 0.0020],\n",
      "         [0.0015, 0.0019, 0.0037,  ..., 0.0020, 0.0019, 0.0022],\n",
      "         ...,\n",
      "         [0.0033, 0.0098, 0.0026,  ..., 0.0031, 0.0023, 0.0038],\n",
      "         [0.0037, 0.0060, 0.0024,  ..., 0.0034, 0.0022, 0.0032],\n",
      "         [0.0039, 0.0064, 0.0025,  ..., 0.0032, 0.0026, 0.0036]]],\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [409]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, one_hot_encoder(tgt, vocab_size))\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniforge3/envs/erxn/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/erxn/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                         betas=(0.9,0.998),\n",
    "                                         lr=1e-3,\n",
    "                                         weight_decay=0.01\n",
    "                                )\n",
    "num_epochs = 10\n",
    "train_loss, test_loss = [], []\n",
    "summary = []\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss = 0\n",
    "    model.train()\n",
    "    for i, (src, tgt, _, _) in enumerate(train_loader):\n",
    "        # attach to device\n",
    "        src = src.to(device)\n",
    "        trg = tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out = model(src, tgt)\n",
    "        \n",
    "        loss = criterion(out, one_hot_encoder(tgt, vocab_size))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.data\n",
    "\n",
    "    train_loss.append(batch_loss / len(train_loader))\n",
    "\n",
    "    batch_loss = 0\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    for i, (src, tgt, _, _) in enumerate(test_loader):\n",
    "        # attach to device\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        pred = model(src, tgt)\n",
    "        loss = criterion(pred, one_hot_encoder(tgt, vocab_size))\n",
    "        \n",
    "        batch_loss += loss.data\n",
    "\n",
    "        acc += get_acc(pred, y_test)\n",
    "        \n",
    "        \n",
    "    test_loss.append(batch_loss / len(test_loader))\n",
    "    acc = acc / len(test_loader)\n",
    "    \n",
    "    if epoch % (1) == 0:\n",
    "        summary.append('Train Epoch: {}\\tLoss: {:.6f}\\tTest Loss: {:.6f}\\tTest Acc: {:.6f} %'.format(epoch, train_loss[-1], test_loss[-1], acc))\n",
    "        print('Train Epoch: {}\\tLoss: {:.6f}\\tTest Loss: {:.6f}\\tTest Acc: {:.6f} %'.format(epoch, train_loss[-1], test_loss[-1], acc))\n",
    "\n",
    "    if invoke(early_stopping, test_loss[-1], model, implement=True):\n",
    "        #model.load_state_dict(torch.load(os.path.join(results_dir,'11_protein_encoder'), map_location=device))\n",
    "        summary.append(f'Early stopping after {epoch} epochs')\n",
    "        break\n",
    "\n",
    "    #torch.save(model.state_dict(), os.path.join(results_dir, f'11_protein_encoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c12bcf4f-cd32-4d7a-98ce-92099ea66b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013157894736842105"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out, tgt = out, one_hot_encoder(tgt, vocab_size)\n",
    "\n",
    "def get_acc(out, tgt):\n",
    "    '''\n",
    "    calculate prediction accuracy\n",
    "    '''\n",
    "    \n",
    "    out_cls = torch.argmax(out[-1], dim=1)\n",
    "    tgt_cls = torch.argmax(tgt[-1], dim=1)\n",
    "    \n",
    "    matches = 0\n",
    "    for i in range(len(out_cls)):\n",
    "        if out_cls[i] == tgt_cls[i]:\n",
    "            matches += 1\n",
    "    \n",
    "    return matches / len(out_cls)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "get_acc(out, one_hot_encoder(tgt, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ff98d590-d726-4600-95ad-f513d5e09ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6672,   -inf,   -inf],\n",
       "          [0.1493, 0.4878,   -inf],\n",
       "          [0.6896, 0.9898, 0.1744]]]])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(3, 3) * float('-inf'), diagonal=1)\n",
    "a = torch.rand((1,1,3,3))\n",
    "a.masked_fill(mask == float('-inf'), float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc1d92-4943-4572-ac57-dc1f4de3a7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
